{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 3401: Project\n",
    "\n",
    "## Author: Harsh Parmar & Shubhkumar Patel\n",
    "\n",
    "**Dataset Source: Suraj, (2023) . _Car Sales Data_ . Kaggle . https://www.kaggle.com/datasets/suraj520/car-sales-data**\n",
    "\n",
    "**Modified Dataset: _Car Sales Data_ . https://media.githubusercontent.com/media/ParmarHarsh/Project-Group-50/main/car_sales_data.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Sales Data\n",
    "\n",
    "**Attributes for car-sales-data.csv dataset:**\n",
    "\n",
    "The below attributes are copied from the original dataset.\n",
    "1. Date: The date of the car sale\n",
    "2. Salesperson: The name of the salesperson who made the sale\n",
    "3. Customer Name: The name of the customer who purchased the car\n",
    "4. Car Make: The make of the car that was purchased\n",
    "5. Car Model: The model of the car that was purchased\n",
    "6. Car Year: The year of the car that was purchased\n",
    "7. Sale Price: The sale price of the car in USD\n",
    "8. Commission Rate: The commission rate paid to the salesperson on the sale\n",
    "9. Commission Earned: The amount of commission earned by the salesperson on the sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Look at the big picture & frame the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the big picture\n",
    "\n",
    "- Predicting future car sales aids manufacturers in planning production, managing inventory, and optimizing marketing strategies based on historical sales data.\n",
    "\n",
    "### Frame the problem\n",
    "\n",
    "- Supervised learning: Using labeled historical data to predict sales figures constitutes a supervised learning problem.\n",
    "- A regression task: Forecasting sales figures from available attributes aligns with regression.\n",
    "- Batch learning: Leveraging the entire dataset to train models for predicting future sales represents batch learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset.\n",
    "url = \"https://media.githubusercontent.com/media/ParmarHarsh/Project-Group-50/main/car_sales_data.csv\"\n",
    "cars = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Create a backup copy of the dataset.\n",
    "cars_backup = cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Take a quick look at the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content of dataset.\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows of dataset.\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of numerical columns.\n",
    "cars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consize summary of dataset.\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of dataset.\n",
    "cars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Explore and visualize the data to gain insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Plot a histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a histogram\n",
    "cars.hist(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Look for correlations between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 - Correlations using Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix.\n",
    "corr_matrix = cars.corr(numeric_only=True)\n",
    "\n",
    "# # Sorting the correlation of 'Sale Price'.\n",
    "corr_matrix[\"Sale Price\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 - Correlations with regard to our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot to visualize the relationship between 'Car Year' and 'Sale Price'.\n",
    "year_vs_price = sns.lineplot(x=\"Car Year\", y=\"Sale Price\", data=cars, errorbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Look at the structure of Car Make and Car Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurrences of each car make in the 'Car Make' column.\n",
    "count_make = cars[\"Car Make\"].value_counts()\n",
    "count_make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurrences of each car model in the 'Car Model' column.\n",
    "count_model = cars[\"Car Model\"].value_counts()\n",
    "count_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a line plot to visualize the relationship between 'Car Make' and 'Sale Price'.\n",
    "make_vs_price = sns.lineplot(x=\"Car Make\", y=\"Sale Price\", data=cars, errorbar=None)\n",
    "\n",
    "# Calculating the average sale price for each car make and sorting in descending order.\n",
    "average_price_by_make = cars.groupby('Car Make')['Sale Price'].mean().sort_values(ascending=False)\n",
    "print(average_price_by_make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a line plot to visualize the relationship between 'Car Model' and 'Sale Price'.\n",
    "model_vs_price = sns.lineplot(x=\"Car Model\", y=\"Sale Price\", data=cars, errorbar=None)\n",
    "\n",
    "# Calculating the average sale price for each car model and sorting in descending order\n",
    "average_price_by_model = cars.groupby('Car Model')['Sale Price'].mean().sort_values(ascending=False)\n",
    "print(average_price_by_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting every 500th row in the dataset.\n",
    "cars = cars.iloc[::500]\n",
    "\n",
    "cars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Check for duplicate rows and remove them if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for and counting duplicated rows.\n",
    "cars.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Handle the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing '?' with NaN (missing value).\n",
    "cars = cars.replace('?', np.nan)\n",
    "\n",
    "# Counting missing values (NaN) in each column.\n",
    "cars.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Create a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features (X) by dropping the \"Sale Price\" column.\n",
    "X = cars.drop([\"Sale Price\"], axis = 1)\n",
    "\n",
    "# Creating the target variable (y) using the \"Sale Price\" column.\n",
    "y = cars[\"Sale Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separating numeric and categorical columns.\n",
    "num_cols = X.select_dtypes(include='number').columns.to_list()\n",
    "cat_cols = X.select_dtypes(exclude='number').columns.to_list()\n",
    "\n",
    "# Creating pipelines for numeric and categorical data.\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "\n",
    "# Combining numeric and categorical preprocessing pipelines using ColumnTransformer.\n",
    "preprocessing = ColumnTransformer([('num', num_pipeline, num_cols), ('cat', cat_pipeline, cat_cols)]\n",
    "                                  , remainder='passthrough')\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "# Performing preprocessing on the features (X).\n",
    "X_prep = preprocessing.fit_transform(X)\n",
    "\n",
    "# Checking if the resulting transformed data is a sparse matrix and converting it to a dense array.\n",
    "if isinstance(X_prep, scipy.sparse.csr_matrix):\n",
    "    X_prep = X_prep.toarray()\n",
    "\n",
    "# Getting feature names after transformation.\n",
    "feature_names = preprocessing.get_feature_names_out()\n",
    "\n",
    "# Creating a DataFrame using the transformed data and the obtained feature names.\n",
    "X_prep = pd.DataFrame(data=X_prep, columns=feature_names)\n",
    "\n",
    "X_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Model Selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Split the testing and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prep, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Training and evaluation of MLAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Creating an instance of the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fitting the Linear Regression model to the training data\n",
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting target values using the Linear Regression model on the test set\n",
    "lr_y_predict = lr_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# Calculating the Mean Squared Error (MSE) between predicted and actual target values\n",
    "lr_mse=mse(y_test, lr_y_predict)\n",
    "\n",
    "print(\"Linear Regression MSE:\", lr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Performing cross-validation on the Linear Regression model\n",
    "# cv=5 specifies 5-fold cross-validation, scoring='neg_mean_squared_error' calculates negative MSE\n",
    "scores = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculating the mean of the negative MSE scores obtained from cross-validation\n",
    "# Multiplying by -1 to revert to positive MSE\n",
    "cross_validation_scores = -scores.mean()\n",
    "\n",
    "print(f'Cross-Validation Mean Score: {cross_validation_scores}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Creating an instance of the Lasso Regression model\n",
    "LassoRegression = Lasso()\n",
    "\n",
    "# Fitting the Lasso Regression model to the training data\n",
    "lasso_model = LassoRegression.fit(X_train, y_train)\n",
    "\n",
    "# Predicting target values using the trained Lasso Regression model on the test set\n",
    "Lasso_y_predict = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculating the Mean Sqaured Error (MSE) between predicted and actual target values\n",
    "lasso_mse=mse(y_test, Lasso_y_predict)\n",
    "\n",
    "print(f'Lasso Regression MAE: {lasso_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of predicted vs actual values using the Linear Regression model\n",
    "plt.scatter(lr_y_predict, y_test)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
